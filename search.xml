<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SpringBoot项目运行显示端口占用问题</title>
    <url>/2024/05/19/SpringBoot%E9%A1%B9%E7%9B%AE%E8%BF%90%E8%A1%8C%E6%98%BE%E7%A4%BA%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>记录一个怪问题</p>
<span id="more"></span>

<h2 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">Web server failed to start. Port 8080 was already <span class="keyword">in</span> use.</span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Identify and stop the process that<span class="string">&#x27;s listening on port 8080 or configure this application to listen on another port.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Process finished with exit code 0</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>

<p>查询端口信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -ano | findstr :8080</span><br><span class="line"> TCP    10.149.0.108:5640      49.7.253.65:8080       ESTABLISHED     27564</span><br></pre></td></tr></table></figure>

<p>杀死端口：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">taskkill /pid 27564 /f</span><br></pre></td></tr></table></figure>

<p>但杀死的端口时qq的，8080端口没有占用后，程序还是报同样的错误</p>
<p>配置文件中换成8081端口后，不报错，但关闭IDEA，又打开后，运行程序显示8081端口被占用。</p>
<p>没找到解决办法，最后重启解决。。。</p>
]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot问题</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World!</title>
    <url>/2024/05/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
<p>hexo g -d： 生成并上传</p>
]]></content>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring容器和注解</title>
    <url>/2024/05/08/newcoder%E9%A1%B9%E7%9B%AE%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86Spring%E5%AE%B9%E5%99%A8%E5%92%8C%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<p>官方文档<a href="https://springdoc.cn/spring/core.htm">https://springdoc.cn/spring/core.htm</a></p>
<span id="more"></span>

<h2 id="Bean和容器"><a href="#Bean和容器" class="headerlink" title="Bean和容器"></a>Bean和容器</h2><p>在spring中，构成程序的骨干和被容器管理的对象称为Bean。</p>
<p><code>org.springframework.context.ApplicationContext</code> 接口代表Spring IoC容器，负责实例化、配置和组装bean。</p>
<p>容器获取Bean的方式有</p>
<ul>
<li>通过类型获取<code>AlphaDao alphaDao = applicationContext.getBean(AlphaDao.class);</code></li>
<li>通过名字获取<code>AlphaDao alphaDao = (AlphaDao) applicationContext.getBean(&quot;alphaHibernate&quot;);</code></li>
</ul>
<p>可以通过<code>XML</code>和注解将Bean实例初始化到容器中。</p>
<h3 id="Primary-注解"><a href="#Primary-注解" class="headerlink" title="@Primary 注解"></a><code>@Primary</code> 注解</h3><p><code>@Primary</code> 表示，当多个Bean是自动注入到一个单值（single value）依赖的候选者时，应该优先考虑一个特定的Bean。如果在候选者中正好有一个主要（primary）Bean存在，它就会成为自动注入的值。</p>
<h3 id="和生命周期有关的注解"><a href="#和生命周期有关的注解" class="headerlink" title="和生命周期有关的注解"></a>和生命周期有关的注解</h3><p><code>@PostConstruct</code> 在构造函数调用后执行</p>
<p><code> @PreDestroy</code>  在销毁前执行</p>
<h3 id="Scope注解"><a href="#Scope注解" class="headerlink" title="@Scope注解"></a><code>@Scope</code>注解</h3><ul>
<li>能够管理Bean的作用域</li>
<li>默认情况下是单例  <code>@Scope(&quot;singleton&quot;)</code></li>
<li>可以变为任何数量的实例  <code>@Scope(&quot;prototype&quot;)</code></li>
</ul>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testBeanManage</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="type">AlphaService</span> <span class="variable">alphaService</span> <span class="operator">=</span> applicationContext.getBean(AlphaService.class);</span><br><span class="line">	System.out.println(alphaService);</span><br><span class="line"></span><br><span class="line">	alphaService = applicationContext.getBean(AlphaService.class);</span><br><span class="line">	System.out.println(alphaService);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Configuration注解"><a href="#Configuration注解" class="headerlink" title="@Configuration注解"></a><code>@Configuration</code>注解</h3><p>被<code>@Configuration</code>标记的类中的<code>@Bean</code>的方法会被Spring容器统一管理</p>
<h3 id="Autowired注解"><a href="#Autowired注解" class="headerlink" title="@Autowired注解"></a><code>@Autowired</code>注解</h3><p>手动获取<code>Bean</code>的方式，用<code>ApplicationContext</code></p>
<p>使用<code>@Autowired</code>可以自动注入<code>bean</code></p>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> AlphaDao alphaDao;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> AlphaService alphaService;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> SimpleDateFormat simpleDateFormat;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testDI</span><span class="params">()</span> &#123;</span><br><span class="line">    System.out.println(alphaDao);</span><br><span class="line">    System.out.println(alphaService);</span><br><span class="line">    System.out.println(simpleDateFormat);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Qualifier注解"><a href="#Qualifier注解" class="headerlink" title="@Qualifier注解"></a><code>@Qualifier</code>注解</h3><p>缩小注入<code>Bean</code>的类型匹配的范围</p>
<h3 id="RequestMapping注解"><a href="#RequestMapping注解" class="headerlink" title="@RequestMapping注解"></a><code>@RequestMapping</code>注解</h3><p>用于映射HTTP请求方式</p>
<ol>
<li><p><code>Get</code>请求获取参数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只有GET方法能请求到</span></span><br><span class="line">   <span class="comment">// /students?current=1&amp;limit=20</span></span><br><span class="line">   <span class="meta">@RequestMapping(value = &quot;/students&quot;, method = RequestMethod.GET)</span></span><br><span class="line">   <span class="meta">@ResponseBody</span></span><br><span class="line">   <span class="keyword">public</span> String <span class="title function_">getStudents</span><span class="params">(</span></span><br><span class="line"><span class="params">           <span class="meta">@RequestParam(name = &quot;current&quot;, required = false, defaultValue = &quot;1&quot;)</span> <span class="type">int</span> current,</span></span><br><span class="line"><span class="params">           <span class="meta">@RequestParam(name = &quot;limit&quot;, required = false, defaultValue = &quot;10&quot;)</span> <span class="type">int</span> limit)</span> &#123;</span><br><span class="line">       System.out.println(current);</span><br><span class="line">       System.out.println(limit);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;some students&quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="comment">// /student/123, 获取参数的方式</span></span><br><span class="line">   <span class="meta">@RequestMapping(value = &quot;/student/&#123;id&#125;&quot;, method = RequestMethod.GET)</span></span><br><span class="line">   <span class="meta">@ResponseBody</span></span><br><span class="line">   <span class="keyword">public</span> String <span class="title function_">getStudent</span><span class="params">(<span class="meta">@PathVariable(name = &quot;id&quot;)</span><span class="type">int</span> id)</span> &#123;</span><br><span class="line">       System.out.println(id);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;a student&quot;</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p><code>Post</code>请求获取参数</p>
<p>场景：路径的长度是有限的，无法在路径中获取很多的参数，因此使用<code>POST</code>请求接收数据。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// POST请求</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/student&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">saveStudent</span><span class="params">(String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">    System.out.println(name);</span><br><span class="line">    System.out.println(age);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="ResponseBody注解"><a href="#ResponseBody注解" class="headerlink" title="@ResponseBody注解"></a><code>@ResponseBody</code>注解</h3><p>将方法的返回值直接作为HTTP响应的内容返回</p>
<p>不加这个注解，默认返回<code>HTML</code>数据</p>
<h3 id="RequestParam注解"><a href="#RequestParam注解" class="headerlink" title="@RequestParam注解"></a><code>@RequestParam</code>注解</h3><p>用于获取 HTTP 请求中的请求参数，从请求的查询参数中获取参数值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping(value = &quot;/students&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getStudents</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="meta">@RequestParam(name = &quot;current&quot;, required = false, defaultValue = &quot;1&quot;)</span> <span class="type">int</span> current,</span></span><br><span class="line"><span class="params">    <span class="meta">@RequestParam(name = &quot;limit&quot;, required = false, defaultValue = &quot;1&quot;)</span> <span class="type">int</span> limit)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;some students&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将<code>request</code>中名为<code>current</code>的参数赋值给函数中的<code>current</code>参数，<code>required = false</code>表示<code>request</code>中可以没有这个参数，<code>defaultValue</code>表示请求中没有这个参数时默认值为1。</p>
<h3 id="PathVariable注解"><a href="#PathVariable注解" class="headerlink" title="@PathVariable注解"></a><code>@PathVariable</code>注解</h3><p>用于获取 URL 中的路径变量的值，从请求的URL路径中获取参数值</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// /student/123, 获取参数的方式</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/student/&#123;id&#125;&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getStudent</span><span class="params">(<span class="meta">@PathVariable(name = &quot;id&quot;)</span><span class="type">int</span> id)</span> &#123;</span><br><span class="line">    System.out.println(id);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;a student&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Component-注解"><a href="#Component-注解" class="headerlink" title="@Component 注解"></a><code>@Component</code> 注解</h3><p><code>@Component</code> 注解应用于类上，以指示该类是一个spring所管理的组件。</p>
<h3 id="Value-注解"><a href="#Value-注解" class="headerlink" title="@Value 注解"></a><code>@Value</code> 注解</h3><p><code>@Value</code> 注解用于将配置属性的值注入到Spring管理的Bean的字段中</p>
<h3 id="Options注解"><a href="#Options注解" class="headerlink" title="@Options注解"></a><code>@Options</code>注解</h3><p>数据库相关配置</p>
<p><code>@Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;)</code>：表示主键自生成</p>
<h2 id="Java项目中的三层"><a href="#Java项目中的三层" class="headerlink" title="Java项目中的三层"></a>Java项目中的三层</h2><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a><code>Controller</code></h3><p>”业务控制层“</p>
<p>处理浏览器的请求，调用业务组件<code>Service</code></p>
<p>控制器层负责处理客户端发起的HTTP请求，并将请求转发给业务逻辑处理层（Service层）进行处理。</p>
<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a><code>Service</code></h3><p>”业务服务层“</p>
<p>业务逻辑层通常包含一组Service类，每个Service类对应系统中的一个业务模块，负责实现该模块的具体业务逻辑。</p>
<h3 id="Dao"><a href="#Dao" class="headerlink" title="Dao"></a><code>Dao</code></h3><p>”数据库持久层“</p>
<p>数据访问层负责与数据库进行交互，执行数据库操作（增删改查），并将数据传递给业务逻辑层进行处理。</p>
<h2 id="Spring中的常用配置"><a href="#Spring中的常用配置" class="headerlink" title="Spring中的常用配置"></a>Spring中的常用配置</h2><p>查找：<a href="https://docs.spring.io/spring-boot/docs/2.1.1.RELEASE/reference/htmlsingle/#common-application-properties">Spring Boot Reference Guide</a></p>
<p>将需要的配置写入<code>application.properties</code>中</p>
]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>newcoder项目前置知识之Mybatis</title>
    <url>/2024/05/10/newcoder%E9%A1%B9%E7%9B%AE%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86%E4%B9%8BMybatis/</url>
    <content><![CDATA[<p>官方文档<a href="https://mybatis.org/spring/">mybatis-spring</a></p>
<span id="more"></span>

<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><h3 id="SqlSessionFactory"><a href="#SqlSessionFactory" class="headerlink" title="SqlSessionFactory"></a>SqlSessionFactory</h3><p>负责创建SqlSession对象</p>
<h3 id="SqlSession"><a href="#SqlSession" class="headerlink" title="SqlSession"></a>SqlSession</h3><p>用于与数据库进行交互。它提供了各种方法来执行SQL语句、获取Mapper接口的实例以及管理事务</p>
<h3 id="XML配置文件"><a href="#XML配置文件" class="headerlink" title="XML配置文件"></a>XML配置文件</h3><p><code>mybatis</code>底层配置</p>
<p> <code>application.properties</code>配置</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># DataSourceProperties，统一管理连接，反复使用，管理连接池</span></span><br><span class="line"><span class="comment"># 数据库驱动</span></span><br><span class="line"><span class="attr">spring.datasource.driver-class-name</span>=<span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="comment"># 数据库地址</span></span><br><span class="line"><span class="attr">spring.datasource.url</span>=<span class="string">jdbc:mysql://localhost:3306/community?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=HongKong</span></span><br><span class="line"><span class="comment"># 数据库用户名</span></span><br><span class="line"><span class="attr">spring.datasource.username</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">spring.datasource.password</span>=<span class="string">123456</span></span><br><span class="line"><span class="comment"># 连接池</span></span><br><span class="line"><span class="attr">spring.datasource.type</span>=<span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line"><span class="comment"># 连接池最大连接数</span></span><br><span class="line"><span class="attr">spring.datasource.hikari.maximum-pool-size</span>=<span class="string">15</span></span><br><span class="line"><span class="comment"># 连接池最小空闲连接</span></span><br><span class="line"><span class="attr">spring.datasource.hikari.minimum-idle</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"># 连接池等多久把空闲的关掉</span></span><br><span class="line"><span class="attr">spring.datasource.hikari.idle-timeout</span>=<span class="string">30000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># MybatisProperties</span></span><br><span class="line"><span class="comment"># 映射文件存放位置</span></span><br><span class="line"><span class="attr">mybatis.mapper-locations</span>=<span class="string">classpath:mapper/*.xml</span></span><br><span class="line"><span class="comment"># 实体类所在包名，封装某个表的数据</span></span><br><span class="line"><span class="attr">mybatis.type-aliases-package</span>=<span class="string">com.newcoder.community.entity</span></span><br><span class="line"><span class="comment"># 启动id自增长</span></span><br><span class="line"><span class="attr">mybatis.configuration.use-generated-keys</span>=<span class="string">true</span></span><br><span class="line"><span class="comment"># 表的字段不区分大小写，属性名是驼峰命令，这个属性让表的字段和属性相匹配</span></span><br><span class="line"><span class="attr">mybatis.configuration.map-underscore-to-camel-case</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>



<h3 id="Mapper接口"><a href="#Mapper接口" class="headerlink" title="Mapper接口"></a>Mapper接口</h3><p>定义数据访问操作的接口，通常对应于数据库中的一个表或一个实体</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Mapper</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserMapper</span> &#123;</span><br><span class="line"></span><br><span class="line">    User <span class="title function_">selectId</span><span class="params">(<span class="type">int</span> id)</span>;</span><br><span class="line">    User <span class="title function_">selectByName</span><span class="params">(String username)</span>;</span><br><span class="line">    User <span class="title function_">selectByEmail</span><span class="params">(String email)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">insertUser</span><span class="params">(User user)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">updateStatus</span><span class="params">(<span class="type">int</span> id, <span class="type">int</span> status)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">updateHeader</span><span class="params">(<span class="type">int</span> id, String headUrl)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">updatePassword</span><span class="params">(<span class="type">int</span> id, String password)</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Mapper映射器"><a href="#Mapper映射器" class="headerlink" title="Mapper映射器"></a>Mapper映射器</h3><p>用于将Mapper接口中的方法与对应的SQL语句进行映射，可以用XML也可以用注解写。</p>
<p>对<code>UserMapper</code>中每一个方法都要写一个标签对应，很容易写错</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">mapper</span></span></span><br><span class="line"><span class="meta">        <span class="keyword">PUBLIC</span> <span class="string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">        <span class="string">&quot;https://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;com.newcoder.community.dao.UserMapper&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sql</span> <span class="attr">id</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span></span><br><span class="line">        id, username, password, salt, email, type, status, activation_code, header_url, create_time</span><br><span class="line">    <span class="tag">&lt;/<span class="name">sql</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sql</span> <span class="attr">id</span>=<span class="string">&quot;insertFile&quot;</span>&gt;</span></span><br><span class="line">        username, password, salt, email, type, status, activation_code, header_url, create_time</span><br><span class="line">    <span class="tag">&lt;/<span class="name">sql</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectById&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;User&quot;</span>&gt;</span></span><br><span class="line">        select <span class="tag">&lt;<span class="name">include</span> <span class="attr">refid</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">        from user</span><br><span class="line">        where id = #&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectByName&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;User&quot;</span>&gt;</span></span><br><span class="line">        select <span class="tag">&lt;<span class="name">include</span> <span class="attr">refid</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">        from user</span><br><span class="line">        where username = #&#123;username&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectByEmail&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;User&quot;</span>&gt;</span></span><br><span class="line">        select <span class="tag">&lt;<span class="name">include</span> <span class="attr">refid</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">        from user</span><br><span class="line">        where email = #&#123;email&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insertUser&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;User&quot;</span>  <span class="attr">keyProperty</span>=<span class="string">&quot;id&quot;</span>&gt;</span></span><br><span class="line">        insert into user (<span class="tag">&lt;<span class="name">include</span> <span class="attr">refid</span>=<span class="string">&quot;insertFile&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">include</span>&gt;</span>)</span><br><span class="line">        value (#&#123;username&#125;, #&#123;password&#125;, #&#123;salt&#125;, #&#123;email&#125;, #&#123;type&#125;, #&#123;status&#125;, #&#123;activationCode&#125;, #&#123;headerUrl&#125;,</span><br><span class="line">        #&#123;createTime&#125;)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updateStatus&quot;</span>&gt;</span></span><br><span class="line">        update user set status = #&#123;status&#125; where id = #&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updateHeader&quot;</span>&gt;</span></span><br><span class="line">        update user set header_url = #&#123;headerUrl&#125; where id = #&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">update</span> <span class="attr">id</span>=<span class="string">&quot;updatePassword&quot;</span>&gt;</span></span><br><span class="line">        update user set password = #&#123;password&#125; where id = #&#123;id&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">update</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">delete</span> <span class="attr">id</span>=<span class="string">&quot;deleteByName&quot;</span>&gt;</span></span><br><span class="line">        delete</span><br><span class="line">        from user</span><br><span class="line">        where username = #&#123;username&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">delete</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="Mybatis的注解"><a href="#Mybatis的注解" class="headerlink" title="Mybatis的注解"></a><code>Mybatis</code>的注解</h2><h3 id="Param注解"><a href="#Param注解" class="headerlink" title="@Param注解"></a><code>@Param</code>注解</h3><p>用于解决方法参数与SQL语句中的参数对应关系不明确的情况，给参数名起别名</p>
<p><code>XML</code>文件中使用动态SQL，要拼接SQL语句时，参数中一定要用<code>@Param</code>注解</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="1-连不上数据库"><a href="#1-连不上数据库" class="headerlink" title="1. 连不上数据库"></a>1. 连不上数据库</h3><p>报错:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: </span><br><span class="line"><span class="comment">### Error querying database.  Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (using password: YES)</span></span><br><span class="line"><span class="comment">### The error may exist in file [D:\learning\projects\newcoder\community\target\classes\mapper\user-mapper.xml]</span></span><br><span class="line"><span class="comment">### The error may involve com.newcoder.community.dao.UserMapper.selectById</span></span><br><span class="line"><span class="comment">### The error occurred while executing a query</span></span><br><span class="line"><span class="comment">### Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (using password: YES)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可能的原因：</p>
<ol>
<li>用户名，密码写错</li>
<li>查询数据库的语句写错</li>
<li>数据库的连接地址不对</li>
</ol>
<p>我的问题是，查询语句中的属性名写错了。</p>
<p>在mapper文件中表名爆红，不会报错。</p>
<p>为了便于调试可以把日志级别在配置里改为<code>debug</code></p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># logger</span></span><br><span class="line"><span class="attr">logging.level.com.newcoder.community</span>=<span class="string">debug</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>newcoder项目前置知识之SpringMVC</title>
    <url>/2024/05/08/newcoder%E9%A1%B9%E7%9B%AE%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86%E4%B9%8BSpringMVC/</url>
    <content><![CDATA[<p>官方文档：<a href="https://springdoc.cn/spring/web.html#mvc">Servlet 栈的 Web 应用 (springdoc.cn)</a></p>
<span id="more"></span>

<h2 id="SpringMVC三层架构"><a href="#SpringMVC三层架构" class="headerlink" title="SpringMVC三层架构"></a>SpringMVC三层架构</h2><p><code>Spring</code>是分为三层：表现层、业务层、数据层</p>
<p><code>SpringMVC</code>：服务于表现层，将表现层分为<code>controller</code>（控制层）、<code>model</code>（模型层）、<code>view</code>（视图层）</p>
<p>model层已有，需要自己写的是<code>controller</code>和模板引擎（<code>thymeleaf</code>）</p>
<h2 id="请求响应数据"><a href="#请求响应数据" class="headerlink" title="请求响应数据"></a>请求响应数据</h2><h3 id="1-响应String类型数据"><a href="#1-响应String类型数据" class="headerlink" title="1.响应String类型数据"></a>1.响应String类型数据</h3><p>将方法的返回值直接作为HTTP响应的内容返回</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只有GET方法能请求到</span></span><br><span class="line"><span class="comment">// /students?current=1&amp;limit=20</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/students&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getStudents</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="meta">@RequestParam(name = &quot;current&quot;, required = false, defaultValue = &quot;1&quot;)</span> <span class="type">int</span> current,</span></span><br><span class="line"><span class="params">        <span class="meta">@RequestParam(name = &quot;limit&quot;, required = false, defaultValue = &quot;10&quot;)</span> <span class="type">int</span> limit)</span> &#123;</span><br><span class="line">    System.out.println(current);</span><br><span class="line">    System.out.println(limit);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;some students&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// /student/123, 获取参数的方式</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/student/&#123;id&#125;&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getStudent</span><span class="params">(<span class="meta">@PathVariable(name = &quot;id&quot;)</span><span class="type">int</span> id)</span> &#123;</span><br><span class="line">    System.out.println(id);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;a student&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// POST请求</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/student&quot;, method = RequestMethod.POST)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">saveStudent</span><span class="params">(String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">    System.out.println(name);</span><br><span class="line">    System.out.println(age);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="2-响应HTML数据"><a href="#2-响应HTML数据" class="headerlink" title="2. 响应HTML数据"></a>2. 响应HTML数据</h3><p>SpringMVC会根据视图解析器将逻辑视图名称解析成实际的视图文件路径，然后将模型中的数据渲染到该视图文件中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="comment">// 响应HTML数据</span></span><br><span class="line">   <span class="meta">@RequestMapping(value = &quot;/teacher&quot;, method = RequestMethod.GET)</span></span><br><span class="line">   <span class="keyword">public</span> ModelAndView <span class="title function_">getTeacher</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="type">ModelAndView</span> <span class="variable">mav</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ModelAndView</span>();</span><br><span class="line">       mav.addObject(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;gxy&quot;</span>);</span><br><span class="line">       mav.addObject(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;22&quot;</span>);</span><br><span class="line">       mav.setViewName(<span class="string">&quot;/demo/view&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> mav;</span><br><span class="line">   &#125;</span><br><span class="line"><span class="comment">// 更为简洁的方法</span></span><br><span class="line">   <span class="meta">@RequestMapping(value = &quot;/school&quot;, method = RequestMethod.GET)</span></span><br><span class="line">   <span class="keyword">public</span> String <span class="title function_">getSchool</span><span class="params">(Model model)</span> &#123;</span><br><span class="line">       model.addAttribute(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;ouc&quot;</span>);</span><br><span class="line">       model.addAttribute(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;99&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;/demo/view&quot;</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>视图文件使用<code>thymeleaf</code>模板引擎，用于在HTML页面上生成动态数据</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span> <span class="attr">xmlns:th</span>=<span class="string">&quot;http://www.thymeleaf.org&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Teacher<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span> <span class="attr">th:text</span>=<span class="string">&quot;$&#123;name&#125;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span> <span class="attr">th:text</span>=<span class="string">&quot;$&#123;age&#125;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-响应JSON数据"><a href="#3-响应JSON数据" class="headerlink" title="3. 响应JSON数据"></a>3. 响应JSON数据</h3><p>一般用于异步请求中，异步请求通俗说就是不刷新页面，但访问了服务器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 相应JSON数据（一般在异步请求中）</span></span><br><span class="line"><span class="comment">// 通过JSON字符串，JAVA对象可以转成JS对象</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/emp&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title function_">getEmp</span><span class="params">()</span> &#123;</span><br><span class="line">    Map&lt;String, Object&gt; emp = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    emp.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;gxy&quot;</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;age&quot;</span>, <span class="number">23</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;salary&quot;</span>, <span class="string">&quot;15k&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> emp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/emps&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="keyword">public</span> List&lt;Map&lt;String, Object&gt;&gt; <span class="title function_">getEmps</span><span class="params">()</span> &#123;</span><br><span class="line">    List&lt;Map&lt;String, Object&gt;&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    Map&lt;String, Object&gt; emp = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    emp.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;gxy&quot;</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;age&quot;</span>, <span class="number">23</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;salary&quot;</span>, <span class="string">&quot;15k&quot;</span>);</span><br><span class="line">    list.add(emp);</span><br><span class="line"></span><br><span class="line">    emp.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;hyy&quot;</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;age&quot;</span>, <span class="number">19</span>);</span><br><span class="line">    emp.put(<span class="string">&quot;salary&quot;</span>, <span class="string">&quot;15k&quot;</span>);</span><br><span class="line">    list.add(emp);</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-响应图片数据"><a href="#4-响应图片数据" class="headerlink" title="4. 响应图片数据"></a>4. 响应图片数据</h3><p>返回一个图片，示例为响应验证码图片</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping(path = &quot;/kaptcha&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getKaptcha</span><span class="params">(HttpServletResponse response, HttpSession session)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> kaptchaProducer.createText();</span><br><span class="line">    <span class="type">BufferedImage</span> <span class="variable">image</span> <span class="operator">=</span> kaptchaProducer.createImage(text);</span><br><span class="line">    <span class="comment">// 将验证码返回给session</span></span><br><span class="line">    session.setAttribute(<span class="string">&quot;kaptcha&quot;</span>, text);</span><br><span class="line">    <span class="comment">// 设置响应类型</span></span><br><span class="line">    response.setContentType(<span class="string">&quot;image/png&quot;</span>);</span><br><span class="line">    <span class="comment">// 将图片输出给浏览器(将生成的图片写入响应数据流)</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> response.getOutputStream();</span><br><span class="line">        ImageIO.write(image, <span class="string">&quot;png&quot;</span>, os);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        logger.error(<span class="string">&quot;响应验证码失败&quot;</span> + e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title>学习小土堆pytorch教程记录-环境配置</title>
    <url>/2024/07/31/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>好久没更了，破事太多了，论坛项目也得先放一放了，先入门pytorch吧，9小时争取尽快学完！</p>
<span id="more"></span>

<h1 id="1-安装anaconda3"><a href="#1-安装anaconda3" class="headerlink" title="1. 安装anaconda3"></a>1. 安装anaconda3</h1><p>anaconda：是包管理和环境管理工具。<br>官网：<a href="https://www.anaconda.com/download#">Download Anaconda Distribution | Anaconda</a><br>镜像：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">Index of &#x2F;anaconda&#x2F;archive&#x2F; | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror</a><br>根据系统下载适合的版本：<br>下载了Anaconda3-2023.09-0-Windows-x86_64版本<br>一直点击下一步。<br>安装完后能打开Anaconda Prompt</p>
<h1 id="2-安装显卡驱动"><a href="#2-安装显卡驱动" class="headerlink" title="2. 安装显卡驱动"></a>2. 安装显卡驱动</h1><p>在任务管理器中GPU内，能看到显卡名即安装了驱动。</p>
<h1 id="3-安装一个环境"><a href="#3-安装一个环境" class="headerlink" title="3. 安装一个环境"></a>3. 安装一个环境</h1><p><strong>更改安装的环境位置：</strong><br>找到.condarc这个文件，加上一个配置，这样就会安装到anaconda的envs下了。更改路径后要给D盘的anaconda文件夹增加权限，所有用户都可读写。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">envs_dirs:</span><br><span class="line">  - D:\anaconda\envs</span><br><span class="line">pkgs_dirs:</span><br><span class="line">  - D:\anaconda\pkgs</span><br></pre></td></tr></table></figure>

<p>打开Anaconda Prompt<br>输入：conda create -n pytorch python&#x3D;3.8<br>激活环境：conda activate pytorch<br>查看有哪些虚拟环境：conda env list<br>退出虚拟环境：conda deactivate<br>删除虚拟环境：conda remove –name env_name –all<br>根据有的配置文件创建环境：conda env create -f environment.yml</p>
<h1 id="4-安装pytorch"><a href="#4-安装pytorch" class="headerlink" title="4. 安装pytorch"></a>4. 安装pytorch</h1><p>pytorch官网：<a href="https://pytorch.org/">PyTorch</a><br>根据是否有GPU选择不同的版本：</p>
<h2 id="有GPU"><a href="#有GPU" class="headerlink" title="有GPU"></a>有GPU</h2><p><img src="/2024/07/31/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/1.png" alt="1"><br>pip3 install torch torchvision torchaudio –index-url <a href="https://download.pytorch.org/whl/cu118">https://download.pytorch.org/whl/cu118</a></p>
<h2 id="无GPU"><a href="#无GPU" class="headerlink" title="无GPU"></a>无GPU</h2><p><img src="/2024/07/31/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/2.png" alt="2"><br>pip3 install torch torchvision torchaudio</p>
<p>验证pytorch是否安装成功：<br><img src="/2024/07/31/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/3.png" alt="3"></p>
<h1 id="5-配置jupyter程序"><a href="#5-配置jupyter程序" class="headerlink" title="5. 配置jupyter程序"></a>5. 配置jupyter程序</h1><p>jupyter是可交互的python编程<br>安装必要的包：conda install nb_conda<br>启动jupyter：jupyter notebook<br>启动后会在浏览器中运行jupyter</p>
<h1 id="6-vscode配置anaconda环境"><a href="#6-vscode配置anaconda环境" class="headerlink" title="6. vscode配置anaconda环境"></a>6. vscode配置anaconda环境</h1><p><strong>需要安装的插件：</strong> python、coder_runner<br>ctrl+shift+p打开后输入python select interpreter<br>find选择anaconda下的一个python.exe</p>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>深度学习 pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>学习小土堆pytorch教程记录-pytorch基础用法</title>
    <url>/2024/08/29/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-pytorch%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<p>继续学了，注意要多看官方文档，看源码，看模块的输入和输出</p>
<span id="more"></span>

<h1 id="1-python文件、python控制台和jupter的不同"><a href="#1-python文件、python控制台和jupter的不同" class="headerlink" title="1. python文件、python控制台和jupter的不同"></a>1. python文件、python控制台和jupter的不同</h1><p>运行同一块代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Start&quot;</span>)</span><br><span class="line">a = <span class="string">&quot;hello world&quot;</span></span><br><span class="line">b = <span class="string">&quot;2024&quot;</span></span><br><span class="line">c = a + b</span><br><span class="line"><span class="built_in">print</span>(c)</span><br></pre></td></tr></table></figure>
<p>python文件是以整体代码为一块运行的<br>python控制台是以每一行为一块运行的（也能以任意行运行）<br>jupyter是以任意行为块运行的<br>后两者，当某一块出错时，修改后前面的块并不需要再次运行。</p>
<table>
<thead>
<tr>
<th>运行方式</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>python文件</td>
<td>传播方便、适用大型项目</td>
<td>需要从头运行</td>
</tr>
<tr>
<td>python控制台</td>
<td>显示每个变量属性</td>
<td>不利于代码阅读和修改</td>
</tr>
<tr>
<td>jupyter</td>
<td>利于代码阅读和修改</td>
<td>环境需要配置</td>
</tr>
</tbody></table>
<h1 id="2-pytorch加载数据"><a href="#2-pytorch加载数据" class="headerlink" title="2. pytorch加载数据"></a>2. pytorch加载数据</h1><p>使用Dataset加载处理图像数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># help(Dataset)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 继承dataset类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyData</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, label_dir</span>): </span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.label_dir = label_dir</span><br><span class="line">        self.path = os.path.join(self.root_dir, self.label_dir)</span><br><span class="line">        self.img_list = os.listdir(self.path)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_name = self.img_list[idx]</span><br><span class="line">        img_item_path = os.path.join(self.path, img_name)</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_item_path)</span><br><span class="line">        label = self.label_dir</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_list)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 实例化对象</span></span><br><span class="line">root_dir = <span class="string">&quot;dataset/train&quot;</span></span><br><span class="line">ants_label_dir = <span class="string">&quot;ants&quot;</span></span><br><span class="line">bees_label_dir = <span class="string">&quot;bees&quot;</span></span><br><span class="line">ants_dataset = MyData(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset = MyData(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line">img, label = ants_dataset[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># img.show()</span></span><br><span class="line"></span><br><span class="line">train_data = ants_dataset + bees_dataset</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_data))</span><br><span class="line"></span><br><span class="line">img, label = train_data[<span class="number">125</span>]</span><br><span class="line">img.show()</span><br></pre></td></tr></table></figure>

<h1 id="3-Tensorboard的使用"><a href="#3-Tensorboard的使用" class="headerlink" title="3. Tensorboard的使用"></a>3. Tensorboard的使用</h1><p>安装tensorboard<br><code>conda install tensorboard</code><br>作用：画网格结构图，精确率、学习率、损失曲线</p>
<p><strong>add_scalar示例：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>, i * <span class="number">2</span>, i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>打开tensorboard查看：<br>(pytorch) D:\learning\pytorch&gt; tensorboard –logdir&#x3D;logs<br>指定端口打开：<br>(pytorch) D:\learning\pytorch&gt;tensorboard –logdir&#x3D;logs –port&#x3D;6007</p>
<p><strong>add_image示例：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(100):</span></span><br><span class="line"><span class="comment">#     writer.add_scalar(&quot;y=2x&quot;, i * 3, i)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># writer.close()</span></span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;dataset/train/bees_image/16838648_415acd9e3f.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(img))</span><br><span class="line">numpy_img = np.array(img)</span><br><span class="line"><span class="built_in">print</span>(numpy_img.shape)</span><br><span class="line">writer.add_image(<span class="string">&quot;test&quot;</span>, numpy_img, <span class="number">2</span>, dataformats=<span class="string">&quot;HWC&quot;</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="3-Transform的使用"><a href="#3-Transform的使用" class="headerlink" title="3. Transform的使用"></a>3. Transform的使用</h1><p><strong>transform.ToTensor示例：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter </span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;dataset/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如何使用transforms</span></span><br><span class="line"><span class="comment"># tensor_img = transforms.ToTensor()(img)</span></span><br><span class="line">tensor_trans = transforms.ToTensor()</span><br><span class="line">tensor_img = tensor_trans(img)</span><br><span class="line"><span class="built_in">print</span>(tensor_img)</span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">&quot;Tensor_img&quot;</span>, tensor_img)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="4-常见的transforms"><a href="#4-常见的transforms" class="headerlink" title="4. 常见的transforms"></a>4. 常见的transforms</h1><h2 id="Normalize的使用"><a href="#Normalize的使用" class="headerlink" title="Normalize的使用"></a>Normalize的使用</h2><p>作用是将输入图像的像素值缩放到一个标准化的范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;dataset/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">tensor_trans = transforms.ToTensor()</span><br><span class="line">tensor_img = tensor_trans(img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tensor_img[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"><span class="comment"># Normalize使用</span></span><br><span class="line">trans_norm = transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">img_norms =trans_norm(tensor_img)</span><br><span class="line"><span class="built_in">print</span>(img_norms[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">writer.add_image(<span class="string">&quot;Normalize_img&quot;</span>, img_norms)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h2 id="Resize的使用"><a href="#Resize的使用" class="headerlink" title="Resize的使用"></a>Resize的使用</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Resize使用</span></span><br><span class="line"><span class="built_in">print</span>(img.size)</span><br><span class="line">trans_resize = transforms.Resize((<span class="number">512</span>, <span class="number">512</span>))</span><br><span class="line"><span class="comment"># img PIL -&gt; Resize -&gt; img_resize PIL</span></span><br><span class="line">img_resize = trans_resize(img)</span><br><span class="line"><span class="comment"># img_resize PIL -&gt; ToTensor -&gt; img_resize tensor</span></span><br><span class="line">img_resize = tensor_trans(img_resize)</span><br><span class="line"><span class="built_in">print</span>(img_resize.size)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize_img&quot;</span>, img_resize)</span><br></pre></td></tr></table></figure>

<h2 id="Compose的使用"><a href="#Compose的使用" class="headerlink" title="Compose的使用"></a>Compose的使用</h2><p>作用时将多个图像变换操作组合在一起，使得它们可以依次对图像进行处理。前一个操作的输出作为后一个操作的输入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compose -&gt; Resize -&gt; ToTensor</span></span><br><span class="line">trans_resize_2 = transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># PIL -&gt; PIL -&gt; Tensor</span></span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2, tensor_trans])</span><br><span class="line">img_resize_2 = trans_compose(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize_img_2&quot;</span>, img_resize_2)</span><br></pre></td></tr></table></figure>

<h2 id="RandomCrop使用"><a href="#RandomCrop使用" class="headerlink" title="RandomCrop使用"></a>RandomCrop使用</h2><p>作用是从图像中随机裁剪出一个指定大小的区域</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RandomCrop使用</span></span><br><span class="line">trans_crop = transforms.RandomCrop(<span class="number">256</span>)</span><br><span class="line">trans_compose_2 = transforms.Compose([trans_crop, tensor_trans])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img_crop = trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">&quot;RandomCrop_img&quot;</span>, img_crop, i)</span><br></pre></td></tr></table></figure>

<h1 id="5-使用torchvision提供的数据集"><a href="#5-使用torchvision提供的数据集" class="headerlink" title="5. 使用torchvision提供的数据集"></a>5. 使用torchvision提供的数据集</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">True</span>, transform=dataset_transform, download=<span class="literal">True</span>)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=dataset_transform, download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(train_set[0])</span></span><br><span class="line"><span class="comment"># print(train_set.classes)</span></span><br><span class="line"><span class="comment"># img, target = train_set[0]</span></span><br><span class="line"><span class="comment"># print(img)</span></span><br><span class="line"><span class="comment"># print(target)</span></span><br><span class="line"><span class="comment"># img.show()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(test_set[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img, target = test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">&quot;test_set&quot;</span>, img, i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="6-DataLoader的使用"><a href="#6-DataLoader的使用" class="headerlink" title="6. DataLoader的使用"></a>6. DataLoader的使用</h1><p>用于从 Dataset中批量加载数据，支持批量处理、打乱和并行加载等功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备的测试数据集</span></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># drop_last=True: 如果最后一个batch的数据量小于batch_size，就把这个batch丢掉</span></span><br><span class="line"><span class="comment"># shuffle=True: 每个epoch都打乱数据</span></span><br><span class="line">test_loader = DataLoader(test_set, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据中的第一张图片和target</span></span><br><span class="line">img, target = test_set[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        <span class="comment"># print(imgs.shape)</span></span><br><span class="line">        <span class="comment"># print(targets)</span></span><br><span class="line">        writer.add_images(<span class="string">&quot;Epoch:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch), imgs, step)</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>深度学习 pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>学习小土堆pytorch教程记录-神经网络基础</title>
    <url>/2024/08/30/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>神经网络的基本骨架、卷积操作、卷积层、最大池化层、非线性激活、线性层、Sequential、损失函数、优化器</p>
<span id="more"></span>

<h1 id="1-神经网络的基本骨架"><a href="#1-神经网络的基本骨架" class="headerlink" title="1. 神经网络的基本骨架"></a>1. 神经网络的基本骨架</h1><p>官方文档：<a href="https://pytorch.org/docs/stable/nn.html">https://pytorch.org/docs/stable/nn.html</a><br>继承nn.Module</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = <span class="built_in">input</span> + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"><span class="built_in">input</span> = torch.tensor(<span class="number">1</span>)</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output) </span><br></pre></td></tr></table></figure>

<h1 id="2-卷积操作"><a href="#2-卷积操作" class="headerlink" title="2. 卷积操作"></a>2. 卷积操作</h1><p>官方文档：<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a><br>stride的作用是卷积核每次移动的步长<br>padding的作用是在输入的边缘补0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5x5的输入</span></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>], </span><br><span class="line">                      [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                      [<span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3x3的卷积核</span></span><br><span class="line">kernel = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(kernel.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">kernel = torch.reshape(kernel, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(kernel.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># stride的作用是卷积核每次移动的步长</span></span><br><span class="line">output = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line">output2 = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(output2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># padding的作用是在输入的边缘补0</span></span><br><span class="line">output3 = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(output3)</span><br></pre></td></tr></table></figure>

<h1 id="3-卷积层"><a href="#3-卷积层" class="headerlink" title="3. 卷积层"></a>3. 卷积层</h1><p>官方文档：<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a><br>示例：<a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</a></p>
<ul>
<li><code>in_channels</code>：输入数据的通道数（例如，RGB图像的通道数为3）。</li>
<li><code>out_channels</code>：卷积核的数量，即输出的特征图数量。</li>
<li><code>kernel_size</code>：卷积核的大小，可以是一个整数或元组（如 <code>3</code> 或 <code>(3, 3)</code>）。</li>
<li><code>stride</code>：卷积操作的步长，默认为 <code>1</code>。</li>
<li><code>padding</code>：在输入的边缘补充的像素数，以控制输出的大小。</li>
<li><code>dilation</code>：卷积核元素之间的间距，默认为 <code>1</code>。</li>
<li><code>bias</code>：是否添加偏置项，默认为 <code>True</code>。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">dataload = DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataload:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    <span class="comment"># print(output.shape)</span></span><br><span class="line">    <span class="comment"># torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line">    <span class="comment"># torch.Size([64, 6, 30, 30])</span></span><br><span class="line"></span><br><span class="line">    output = torch.reshape(output, (-<span class="number">1</span>, <span class="number">3</span>, <span class="number">30</span>, <span class="number">30</span>))</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="4-最大池化层的使用"><a href="#4-最大池化层的使用" class="headerlink" title="4. 最大池化层的使用"></a>4. 最大池化层的使用</h1><p>官方文档：<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d">https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d</a><br>是下采样操作，用于减少数据的空间尺寸（宽度和高度），从而降低计算复杂度。池化层只保留局部区域的最大值，忽略其他较小的值，从而保留最显著的特征，抑制不重要的噪声。<br>参数<code>ceil_mode</code>决定了如何处理池化窗口的边界情况,</p>
<ul>
<li><strong><code>ceil_mode=False</code>（默认）</strong>：输出尺寸的计算采用 <code>floor</code>（向下取整），即舍去小数部分。这意味着在池化过程中，如果最后的窗口未完全覆盖输入的边界部分，则该窗口会被忽略。</li>
<li>**<code>ceil_mode=True</code>**：输出尺寸的计算采用 <code>ceil</code>（向上取整），即向上取整处理。在这种情况下，最后的池化窗口可以扩展到输入边界，即使该窗口未完全覆盖输入边界的数据也会参与计算。这会增加输出的尺寸。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5x5的输入</span></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>], </span><br><span class="line">                      [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                      [<span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="built_in">input</span> = <span class="built_in">input</span>.reshape(<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataload = DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.maxpool(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># output = model(input)</span></span><br><span class="line"><span class="comment"># print(input.shape)</span></span><br><span class="line"><span class="comment"># print(output.shape)</span></span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataload:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="5-非线性激活"><a href="#5-非线性激活" class="headerlink" title="5. 非线性激活"></a>5. 非线性激活</h1><p>官方文档：<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity</a><br>非线性激活函数使得神经网络能够学习和逼近复杂的非线性关系。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sigmoid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, -<span class="number">1.5</span>],</span><br><span class="line">                      [-<span class="number">1</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.relu = ReLU()</span><br><span class="line">        self.sigmoid = Sigmoid()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># output = self.relu(x)</span></span><br><span class="line">        output = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># output = model(input)</span></span><br><span class="line"><span class="comment"># # tensor([[[1., 0.],[0., 3.]]])</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="6-线性层"><a href="#6-线性层" class="headerlink" title="6. 线性层"></a>6. 线性层</h1><p>线性层官方文档：<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear">https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear</a><br>线性层可以改变数据的维度，例如在卷积神经网络中，将卷积层的输出展平（flatten）后通过线性层，将特征映射到最终的类别空间或回归目标空间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">196608</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    img, taget = data</span><br><span class="line">    <span class="built_in">print</span>(img.shape)</span><br><span class="line">    <span class="comment"># output = torch.reshape(img, (1, 1, 1, -1))</span></span><br><span class="line">    output = torch.flatten(img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    output = model(output)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>

<h1 id="7-Sequential使用"><a href="#7-Sequential使用" class="headerlink" title="7. Sequential使用"></a>7. Sequential使用</h1><p>用于将多个层按顺序组合在一起。它的主要用途是简化模型的定义，使代码更加简洁和易读。<br>CIFRA10数据训练的模型结构如下图：<br><img src="/2024/08/30/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1.png" alt="1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        self.maxpool1 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.conv2 = Conv2d(in_channels=<span class="number">32</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        self.maxpool2 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.conv3 = Conv2d(in_channels=<span class="number">32</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        self.maxpool3 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.linear1 = Linear(<span class="number">1024</span>, <span class="number">64</span>)</span><br><span class="line">        self.linear2 = Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sequential的使用</span></span><br><span class="line">        self.model1 = nn.Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x = self.conv1(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool1(x)</span></span><br><span class="line">        <span class="comment"># x = self.conv2(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool2(x)</span></span><br><span class="line">        <span class="comment"># x = self.conv3(x)</span></span><br><span class="line">        <span class="comment"># x = self.maxpool3(x)</span></span><br><span class="line">        <span class="comment"># x = self.flatten(x)</span></span><br><span class="line">        <span class="comment"># x = self.linear1(x)</span></span><br><span class="line">        <span class="comment"># x = self.linear2(x)</span></span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">writer.add_graph(model, <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h1 id="8-损失函数"><a href="#8-损失函数" class="headerlink" title="8. 损失函数"></a>8. 损失函数</h1><p>计算和实际输出之间的差距<br>为反向传播提供依据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss, MSELoss</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.float32)</span><br><span class="line">target = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">target = torch.reshape(target, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss = L1Loss()</span></span><br><span class="line">loss = L1Loss(reduction=<span class="string">&quot;sum&quot;</span>)</span><br><span class="line">result = loss(<span class="built_in">input</span>, target)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">loss_mes = MSELoss()</span><br><span class="line">result_mes = loss_mes(<span class="built_in">input</span>, target)</span><br><span class="line"><span class="built_in">print</span>(result_mes)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line">x = torch.reshape(x, (<span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">loss_cross = torch.nn.CrossEntropyLoss()</span><br><span class="line">result_cross = loss_cross(x, y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>

<p><strong>在神经网络中如何使用损失函数：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sequential的使用</span></span><br><span class="line">        self.model1 = nn.Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># writer = SummaryWriter(&quot;logs&quot;)</span></span><br><span class="line">model = Model()</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = model(imgs)</span><br><span class="line">    <span class="built_in">print</span>(output)</span><br><span class="line">    <span class="built_in">print</span>(targets)</span><br><span class="line">    result_loss = loss(output, targets)</span><br><span class="line">    <span class="built_in">print</span>(result_loss)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="9-优化器"><a href="#9-优化器" class="headerlink" title="9. 优化器"></a>9. 优化器</h1><p>根据计算得到的梯度来更新模型的参数，以最小化损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sequential的使用</span></span><br><span class="line">        self.model1 = nn.Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># writer = SummaryWriter(&quot;logs&quot;)</span></span><br><span class="line">model = Model()</span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        imgs, targets = data</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        result_loss = loss(output, targets)</span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        result_loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        running_loss += result_loss</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;epoch&#125;</span>, loss: <span class="subst">&#123;running_loss&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>深度学习 pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>学习小土堆pytorch教程记录-pytorch模型训练过程</title>
    <url>/2024/09/05/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-pytorch%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>现有网络模型的使用和修改、网络模型的保存和读取、完整的模型训练套路、使用GPU进行训练、完整的模型验证套路</p>
<p>算是学完了基础使用吧，但离实际操作还有很远。</p>
<p>代码的github仓库为：<a href="https://github.com/Eclipse-git725/pytorch">https://github.com/Eclipse-git725/pytorch</a></p>
<span id="more"></span>

<h1 id="1-现有网络模型的使用和修改"><a href="#1-现有网络模型的使用和修改" class="headerlink" title="1. 现有网络模型的使用和修改"></a>1. 现有网络模型的使用和修改</h1><p>官方文档：<a href="https://pytorch.org/vision/stable/index.html">https://pytorch.org/vision/stable/index.html</a><br>imgenet:<a href="https://pytorch.org/vision/0.9/datasets.html#imagenet">https://pytorch.org/vision/0.9/datasets.html#imagenet</a><br>需要先安装scipy包，<code>pip install scipy</code><br>pretrained为True时，模型是在数据集上已经训练好的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 太大了，147G</span></span><br><span class="line"><span class="comment"># dataset = torchvision.datasets.ImageNet(&quot;./dataset&quot;, split=&quot;train&quot;, transform=torchvision.transforms.ToTensor(), download=True)</span></span><br><span class="line"><span class="comment"># dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, drop_last=True)</span></span><br><span class="line"></span><br><span class="line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># vgg16_true = torchvision.models.vgg16(pretrained=True)</span></span><br><span class="line"><span class="comment"># 调试，断点打到这里</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ok&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg16_false)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迁移学习，根据现有网络改变它的结构</span></span><br><span class="line"><span class="comment"># 修改vgg16，in_features=1000，out_features=10</span></span><br><span class="line"><span class="comment"># vgg16_false.add_module(&quot;add_linear&quot;, nn.Linear(1000, 10))</span></span><br><span class="line"><span class="comment"># vgg16_false.classifier.add_module(&quot;add_linear&quot;, nn.Linear(1000, 10))</span></span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>] = nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg16_false)</span><br></pre></td></tr></table></figure>

<h1 id="2-网络模型的保存和读取"><a href="#2-网络模型的保存和读取" class="headerlink" title="2. 网络模型的保存和读取"></a>2. 网络模型的保存和读取</h1><p>模型保存两种方式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 保存方式1，模型结构和模型参数</span></span><br><span class="line">torch.save(vgg16, <span class="string">&#x27;vgg16_method1.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存方式2，模型参数（官方推荐）</span></span><br><span class="line">torch.save(vgg16.state_dict(), <span class="string">&#x27;vgg16_method2.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 陷阱</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.conv2d1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv2d1(x)</span><br><span class="line">    </span><br><span class="line">model = Model()</span><br><span class="line">torch.save(model, <span class="string">&quot;model_method1.pth&quot;</span>) </span><br></pre></td></tr></table></figure>

<p>模型读取两种方式（如果是自己定义的模型需要能访问到自己的模型结构才能加载）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> model_save <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取方式1</span></span><br><span class="line">model = torch.load(<span class="string">&#x27;vgg16_method1.pth&#x27;</span>)</span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取方式2</span></span><br><span class="line">model = torch.load(<span class="string">&#x27;vgg16_method2.pth&#x27;</span>)</span><br><span class="line"><span class="comment"># print(model)</span></span><br><span class="line"><span class="comment"># 只保存参数，如何恢复网络模型，load_state_dict参数里写字典</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&#x27;vgg16_method2.pth&#x27;</span>))</span><br><span class="line"><span class="comment"># print(vgg16)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 陷阱</span></span><br><span class="line"><span class="comment"># class Model(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(Model, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.conv2d1 = nn.Conv2d(3, 64, 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def forward(self, x):</span></span><br><span class="line"><span class="comment">#         return self.conv2d1(x)</span></span><br><span class="line"><span class="comment"># 只写load会报错，需要把模型定义写上，或者用import引入</span></span><br><span class="line">model = torch.load(<span class="string">&#x27;model_method1.pth&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>

<h1 id="3-完整的模型训练套路"><a href="#3-完整的模型训练套路" class="headerlink" title="3. 完整的模型训练套路"></a>3. 完整的模型训练套路</h1><ol>
<li>加载训练数据集和测试数据集</li>
<li>创建神经网络</li>
<li>创建损失函数</li>
<li>创建优化器</li>
<li>设置训练次数、测试次数和训练轮数</li>
<li>开始训练、测试，输出损失、准确率等，以及进行tensorboard可视化<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> model.model <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_set)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试数据集的长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(test_set)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用DataLoader加载数据集</span></span><br><span class="line">train_dataloader = DataLoader(train_set, batch_size=<span class="number">64</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line">test_dataloader = DataLoader(test_set, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建神经网络</span></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建优化器</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的参数</span></span><br><span class="line"><span class="comment"># 记录训练次数</span></span><br><span class="line">total_train_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试次数</span></span><br><span class="line">total_test_step = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录训练轮数</span></span><br><span class="line">epoch = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----------第&#123;&#125;轮训练开始---------&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="comment"># 对特殊的层有影响，比如dropout和batchnorm</span></span><br><span class="line">    model.trian()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        imgs, target = data</span><br><span class="line">        output = model(imgs)</span><br><span class="line">        loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_train_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span>(total_train_step % <span class="number">100</span> == <span class="number">0</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss))</span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>, loss.item(), total_train_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试步骤开始</span></span><br><span class="line">    <span class="comment"># 对特殊的层有影响，比如dropout和batchnorm</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_test_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 分类中的重要参数，正确率</span></span><br><span class="line">    total_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:</span><br><span class="line">            imgs, target = data</span><br><span class="line">            output = model(imgs)</span><br><span class="line">            loss = loss_fn(output, target)</span><br><span class="line">            total_test_loss += loss</span><br><span class="line">            <span class="comment"># 计算正确率</span></span><br><span class="line">            accuracy = (output.argmax(<span class="number">1</span>) == target).<span class="built_in">sum</span>()</span><br><span class="line">            total_accuracy += accuracy</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的loss为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/<span class="built_in">len</span>(test_set)))</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>, total_accuracy/<span class="built_in">len</span>(test_set), total_test_step)</span><br><span class="line">    total_test_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存每一轮训练的模型</span></span><br><span class="line">    torch.save(model, <span class="string">&quot;model/model_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型已保存&quot;</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="4-使用GPU进行训练"><a href="#4-使用GPU进行训练" class="headerlink" title="4. 使用GPU进行训练"></a>4. 使用GPU进行训练</h1><p>只有模型、数据、损失函数可以调用.cuda()函数<br>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    model.cuda()</span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    loss_fn.cuda()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    imgs = imgs.cuda()</span><br><span class="line">    target = target.cuda()</span><br></pre></td></tr></table></figure>
<p>如果电脑没有GPU，可以使用google colab使用GPU训练，有免费额度。<br>使用手机Google可以不用开梯子，不用手机号，就注册上一个google邮箱。<br>设置使用GPU，可想jupyter一样使用。<br><img src="/2024/09/05/%E5%AD%A6%E4%B9%A0%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%E6%95%99%E7%A8%8B%E8%AE%B0%E5%BD%95-pytorch%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B/1.png" alt="1"></p>
<h1 id="5-完整的模型验证套路"><a href="#5-完整的模型验证套路" class="headerlink" title="5. 完整的模型验证套路"></a>5. 完整的模型验证套路</h1><p>利用已经训练好的模型，给它提供输入<br>若是拿GPU训练好的模型，在CPU上验证，在模型load时使用：<br><code>model = torch.load(&quot;./model/model_4.pth&quot;, map_location=torch.device(&#39;cpu&#39;))</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;./imgs/dog.png&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"><span class="built_in">print</span>(img)</span><br><span class="line"></span><br><span class="line">transform = torchvision.transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">img = transform(img)</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br><span class="line">    </span><br><span class="line">model = torch.load(<span class="string">&quot;./model/model_4.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line">img = torch.reshape(img, (<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(img)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="built_in">print</span>(output.argmax(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>深度学习 pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>仿牛客论坛项目01-首页功能</title>
    <url>/2025/03/04/%E4%BB%BF%E7%89%9B%E5%AE%A2%E8%AE%BA%E5%9D%9B%E9%A1%B9%E7%9B%AE01-%E9%A6%96%E9%A1%B5%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>仿牛客论坛项目01-首页功能，内容记录</p>
<span id="more"></span>

<h2 id="1-首页"><a href="#1-首页" class="headerlink" title="1. 首页"></a>1. 首页</h2><p>代码写的顺序：<code>Dao</code>-&gt;<code>Service</code>-&gt;<code>Controller</code></p>
<h3 id="DAO"><a href="#DAO" class="headerlink" title="DAO"></a><code>DAO</code></h3><p>方法1：需要查询所有的帖子，查询所有的不需要参数；考虑到之后还有功能个人主页上显示自己的博客，因此，方法中要加上<code>userID</code>参数；还有分页功能，方法中还要加上页数的索引<code>offset</code>，以及每页的限制<code>limit</code>。</p>
<p>方法2：为了实现分页功能，需要查询所有帖子的行数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Mapper</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">DiscussPostMapper</span> &#123;</span><br><span class="line">    List&lt;DiscussPost&gt; <span class="title function_">selectDiscussPosts</span><span class="params">(<span class="type">int</span> userId, <span class="type">int</span> offset, <span class="type">int</span> limit)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">selectDiscussPostsRows</span><span class="params">(<span class="meta">@Param(&quot;userId&quot;)</span> <span class="type">int</span> userId)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对应的配置文件：</p>
<p>不选择拉黑的帖子，拼接动态SQL</p>
<p>首先按是否置顶排序，再按创建时间降序排序，最近发布的在上面</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">sql</span> <span class="attr">id</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span></span><br><span class="line">       id, user_id, title, content, type, status, create_time, comment_count, score</span><br><span class="line">   <span class="tag">&lt;/<span class="name">sql</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectDiscussPosts&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;DiscussPost&quot;</span>&gt;</span></span><br><span class="line">       select <span class="tag">&lt;<span class="name">include</span> <span class="attr">refid</span>=<span class="string">&quot;selectField&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">       from discuss_post</span><br><span class="line">       where status != 2</span><br><span class="line">       <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;userId != 0&quot;</span>&gt;</span></span><br><span class="line">           and user_id = #&#123;userId&#125;</span><br><span class="line">       <span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">       order by type desc, create_time desc</span><br><span class="line">       limit #&#123;offset&#125;, #&#123;limit&#125;</span><br><span class="line">   <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectDiscussPostsRows&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;int&quot;</span>&gt;</span></span><br><span class="line">       select count(id)</span><br><span class="line">       from discuss_post</span><br><span class="line">       where status != 2</span><br><span class="line">       <span class="tag">&lt;<span class="name">if</span> <span class="attr">test</span>=<span class="string">&quot;userId != 0&quot;</span>&gt;</span></span><br><span class="line">           and user_id = #&#123;userId&#125;</span><br><span class="line">       <span class="tag">&lt;/<span class="name">if</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p><code>DiscussPostService</code>调用<code>Dao</code>层中的方法，并将获取到的数据通过<code>userId</code>和<code>username</code>一起返回，因此还需要一个<code>UserService</code></p>
<h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><p>静态资源、页面导入</p>
<p>在该层中调用<code>Service</code>，返回模板的路径</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RequestMapping(value = &quot;/index&quot;, method = RequestMethod.GET)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">getIndexPage</span><span class="params">(Model model, Page page)</span> &#123;</span><br><span class="line">    <span class="comment">// SpringMVC会将Page自动注入到Model，并将请求中的查询参数映射到这个对象上</span></span><br><span class="line">    <span class="comment">// 这样Thymeleaf可以直接使用Page中的数据</span></span><br><span class="line">    <span class="comment">// 服务端可以设置的分页参数</span></span><br><span class="line">    page.setRows(discussPostService.findDiscussPostsRows(<span class="number">0</span>));</span><br><span class="line">    page.setPath(<span class="string">&quot;/index&quot;</span>);</span><br><span class="line"></span><br><span class="line">    List&lt;DiscussPost&gt; list = discussPostService.findDiscussPosts(<span class="number">0</span>, page.getOffset(), page.getLimit());</span><br><span class="line">    List&lt;Map&lt;String, Object&gt;&gt; postList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="keyword">if</span>(list != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span>(DiscussPost post : list) &#123;</span><br><span class="line">            <span class="comment">// 将用户名加入列表中</span></span><br><span class="line">            <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> userService.findUserById(post.getUserId());</span><br><span class="line">            Map&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">            map.put(<span class="string">&quot;post&quot;</span>, post);</span><br><span class="line">            map.put(<span class="string">&quot;user&quot;</span>, user);</span><br><span class="line">            postList.add(map);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    model.addAttribute(<span class="string">&quot;discussPosts&quot;</span>, postList);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;/index&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-分页功能"><a href="#2-分页功能" class="headerlink" title="2. 分页功能"></a>2. 分页功能</h2><p><strong>分页类需要用到的参数：</strong></p>
<ol>
<li><code>current</code> 为当前页码</li>
<li><code>limit</code> 为每页上限</li>
<li><code>rows</code> 为数据总数</li>
<li><code>path</code> 为查询路径（封装在里面，查询时就不用字符串拼接了）</li>
</ol>
<p>上述参数有限制条件可以在<code>setter</code>中写，比如当前页数不能为负数。</p>
<p><strong>分页类需要用到的方法：</strong></p>
<ol>
<li><code>getOffset</code> 获取当前页的起始行，在数据库查询时需要用到</li>
<li><code>getTotal</code> 获取总页码，页面上显示的页码不能超过总页码</li>
<li><code>getFrom</code>  当页码还要显示前后几个页码，获取这段页码的起始页码</li>
<li><code>getTo</code> 获取这段页码的结束页码</li>
</ol>
<p><code>index</code>页面中分页实现逻辑：</p>
<ol>
<li>没有数据时不需要分页</li>
<li>用遍历显示当前页码，和前两个到后两个的页码</li>
<li>当前页的按钮状态为激活</li>
<li>处于第一页时，上一页禁用</li>
<li>处于最后一页时，下一页禁用</li>
</ol>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 分页 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">&quot;mt-5&quot;</span> <span class="attr">th:if</span>=<span class="string">&quot;$&#123;page.rows&gt;0&#125;&quot;</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">&quot;pagination justify-content-center&quot;</span>&gt;</span></span><br><span class="line">			<span class="comment">&lt;!-- /index?current=1 --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;page-item&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;page-link&quot;</span> <span class="attr">th:href</span>=<span class="string">&quot;@&#123;$&#123;page.path&#125;(current=1)&#125;&quot;</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">li</span> <span class="attr">th:class</span>=<span class="string">&quot;|page-item $&#123;page.current==1?&#x27;disabled&#x27;:&#x27;&#x27;&#125;|&quot;</span> &gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;page-link&quot;</span> <span class="attr">th:href</span>=<span class="string">&quot;@&#123;$&#123;page.path&#125;(current=$&#123;page.current-1&#125;)&#125;&quot;</span>&gt;</span>上一页</span><br><span class="line">			    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">li</span> <span class="attr">th:class</span>=<span class="string">&quot;|page-item $&#123;i==page.current?&#x27;active&#x27;:&#x27;&#x27;&#125;|&quot;</span></span></span><br><span class="line"><span class="tag">				<span class="attr">th:each</span>=<span class="string">&quot;i:$&#123;#numbers.sequence(page.from, page.to)&#125;&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;page-link&quot;</span> <span class="attr">th:href</span>=<span class="string">&quot;@&#123;$&#123;page.path&#125;(current=$&#123;i&#125;)&#125;&quot;</span> <span class="attr">th:text</span>=<span class="string">&quot;$&#123;i&#125;&quot;</span>&gt;</span>1<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">li</span> <span class="attr">th:class</span>=<span class="string">&quot;|page-item $&#123;page.current==page.total?&#x27;disabled&#x27;:&#x27;&#x27;&#125;|&quot;</span> &gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;page-link&quot;</span> <span class="attr">th:href</span>=<span class="string">&quot;@&#123;$&#123;page.path&#125;(current=$&#123;page.current+1&#125;)&#125;&quot;</span>&gt;</span>下一页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;page-item&quot;</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;page-link&quot;</span> <span class="attr">th:href</span>=<span class="string">&quot;@&#123;$&#123;page.path&#125;(current=$&#123;page.total&#125;)&#125;&quot;</span>&gt;</span>末页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h2 id="3-Thymeleaf语法"><a href="#3-Thymeleaf语法" class="headerlink" title="3. Thymeleaf语法"></a>3. Thymeleaf语法</h2><p><strong><code>thymeleaf</code>作用</strong>：前端页面中使用Thymeleaf表达式来访问<code>Model</code>中的数据</p>
<p>导入<code>thymeleaf</code>：<code>&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;</code></p>
<p>页面中导入的静态资源有相对路径时，需要使用<code>thymeleaf</code>语法</p>
<p><code>&lt;link rel=&quot;stylesheet&quot; th:href=&quot;@&#123;css/global.css&#125;&quot; /&gt;</code> 这样写默认去<code>static</code>下寻找</p>
<p>循环：<code>th:each=&quot;map:$&#123;discussPosts&#125;&quot;</code> map是遍历时的元素</p>
<p>内容：<code>th:utext=&quot;$&#123;map.post.title&#125;&quot;</code>  <code>utext</code>可以解析转义字符</p>
<p>判断：<code>th:if=&quot;$&#123;map.post.type==1&#125;&quot;</code></p>
<p>时间格式化：<code>th:text=&quot;$&#123;#dates.format(map.post.createTime, &#39;yyyy-MM-dd HH:mm:ss&#39;)&#125;&quot;</code></p>
<h3 id="Thymeleaf符号"><a href="#Thymeleaf符号" class="headerlink" title="Thymeleaf符号"></a><code>Thymeleaf</code>符号</h3><ol>
<li><p><code>#</code> ：标识Thymeleaf内置的标准表达式对象，如<code>#dates</code>用于日期操作</p>
</li>
<li><p><code>$</code> ：用于获取变量的值，并将其插入到模板中，如<code>post.title</code></p>
</li>
<li><p><code>@</code> ：用于表示Thymeleaf中的URL表达式</p>
</li>
<li><p><code>|</code> ：可以将一个静态的字符串和一个表达式拼接在一起</p>
<p><code>&lt;li th:class=&quot;|page-item $&#123;page.current==page.total?&#39;disabled&#39;:&#39;&#39;&#125;|&quot; &gt;</code></p>
</li>
<li><p><code>th:text</code> ：用于设置标签内文本的值</p>
</li>
<li><p><code>th:if</code> ：用于条件判断，根据条件的真假来显示或隐藏标签</p>
</li>
<li><p><code>th:each</code>：用于遍历集合或数组，将集合中的每个元素逐个处理</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">th:each</span>=<span class="string">&quot;item : $&#123;items&#125;&quot;</span> <span class="attr">th:text</span>=<span class="string">&quot;$&#123;item&#125;&quot;</span>&gt;</span>Item<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>th:href</code>：用于设置链接的URL</p>
</li>
<li><p>&#96;&#96;th:class&#96;：用于设置标签的类名</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">th:class</span>=<span class="string">&quot;$&#123;condition&#125; ? &#x27;class1&#x27; : &#x27;class2&#x27;&quot;</span>&gt;</span>Content<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">li</span> <span class="attr">th:class</span>=<span class="string">&quot;|page-item $&#123;page.current==page.total?&#x27;disabled&#x27;:&#x27;&#x27;&#125;|&quot;</span> &gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>th:fragment</code>：用于定义一个可重用的模板片段，可以在其他模板被引入并重用</p>
</li>
<li><p><code>th:replace</code>：用于在一个模板中引入另一个模板，替换该标签的内容</p>
<p><code>&lt;div th:replace=&quot;fragments :: myFragment&quot;&gt;&lt;/div&gt;</code>表示</p>
</li>
</ol>
<h3 id="Content"><a href="#Content" class="headerlink" title="Content"></a><code>Content</code></h3><p>在Thymeleaf中，<code>context</code>类主要用于传递变量和数据模型到模板引擎，以便在HTML模板中进行数据渲染。</p>
<h2 id="4-问题"><a href="#4-问题" class="headerlink" title="4. 问题"></a>4. 问题</h2><ol>
<li><p>在page类里没有配置total属性，但是有一个getTotal方法，controller类里将page注入给了model，为什么在thymeleaf中可以直接使用page.total，而不用getTotal</p>
<p>尽管<code>Page</code>类没有直接定义一个名为<code>total</code>的属性，但是存在一个<code>getTotal()</code>方法。根据JavaBean的命名规则，Thymeleaf会认为<code>getTotal()</code>方法是用来获取<code>total</code>属性的值的。因此，Thymeleaf允许直接使用<code>page.total</code>来访问这个属性的值，而不需要显式调用<code>getTotal()</code>方法。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java项目</category>
      </categories>
      <tags>
        <tag>Java SpringBoot</tag>
      </tags>
  </entry>
</search>
